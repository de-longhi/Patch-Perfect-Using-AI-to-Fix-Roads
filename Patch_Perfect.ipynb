{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i-ebO8XbEsEd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "plt.ion() # (%matplotlib inline)\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy0o8aeIEsEf"
      },
      "source": [
        "# Patch Perfect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aC__VfxoEsEi"
      },
      "source": [
        "This notebook will document the process we underwent to find a solution to the plothole-problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZOHtzy0EsEj"
      },
      "source": [
        "\n",
        "### EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY7iO0TbEsEj"
      },
      "source": [
        "We start by looking at the data systematically to see where we will inevitably need to solve problems before we create a model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hVhsQ812EsEk"
      },
      "outputs": [],
      "source": [
        "# __file__ = os.path.abspath('') # notebooks are stupid\n",
        "# DATA_DIR = Path(__file__).resolve() / \"data\"\n",
        "# TRAIN_LABELS_PATH = DATA_DIR / \"train_labels.csv\"\n",
        "\n",
        "# train_label_df = pd.read_csv(filepath_or_buffer=TRAIN_LABELS_PATH)\n",
        "# train_label_df.rename(columns={'Bags used ': 'Bags used'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HfVHP5EDEsEl",
        "outputId": "81635175-1a4b-4146-cdea-b6fac2347de5"
      },
      "outputs": [],
      "source": [
        "# values = train_label_df.loc[:, 'Bags used'].value_counts()\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.hist(values, bins=range(1, max(values) + 2), edgecolor='black')\n",
        "# plt.title('Histogram of Data Points per Bag Amount')\n",
        "# plt.xlabel('Number of Data Points for Each Bag Amount')\n",
        "# plt.ylabel('Frequency')\n",
        "# plt.grid(True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMcpWCujEsEn"
      },
      "source": [
        "We can see that there is a massive class imbalance. This could create issues where a model trained on this dataset has a bias towards more common bags. Most values are between 0 and 1 with some values much higher. There are many strategies we could use to solve this, including but not limited to:\n",
        "<ul>\n",
        "<li>Some label abstraction technique where we might create labels based on a logarithmic scale</li>\n",
        "<li>Data augmentation as a class imbalance mitigation: This process is called upsampling</li>\n",
        "</ul>\n",
        "\n",
        "We should also consider the following: The data makes this problem seem like a regression model is needed, but tuning the labels may enable us to change it to a much simpler classification task at the cost of some accuracy. Doing this would result in a much more robust model and enable us to use techniques like label smoothing to let the model generalize more to unseen data.\n",
        "<hr>\n",
        "References:\n",
        "<ul>\n",
        "<li>Paperspace Blog. (2022). Data Augmentation: A Class Imbalance Mitigative Measure. [online] Available at: https://blog.paperspace.com/data-augmentation-a-class-imbalance-mitigative-measure/.</li>\n",
        "<li>S. Wang and X. Yao, \"Multiclass Imbalance Problems: Analysis and Potential Solutions,\" in IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), vol. 42, no. 4, pp. 1119-1130, Aug. 2012, doi: 10.1109/TSMCB.2012.2187280. keywords: {Training;Correlation;Training data;Pattern analysis;Genetic algorithms;IEEE Potentials;Cybernetics;Boosting;diversity;ensemble learning;multiclass imbalance problems;negative correlation learning}, </li>\n",
        "</ul>\n",
        "â€Œ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsDHOvH0EsEp"
      },
      "source": [
        "## The model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kqPHOll3EsEq"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_8824/3933020813.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model = torch.load(\"./pretrained_model.pt\")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "model = torch.load(\"./pretrained_model.pt\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    if(\"bn\" not in name):\n",
        "      param.requires_grad = False\n",
        "\n",
        "\n",
        "model.classifier = nn.Sequential( # Change only the classifier of the model, I.E the last few layers\n",
        "\n",
        "    nn.Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
        "    nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=0.1, inplace=False),\n",
        "    nn.Conv2d(512, 3, kernel_size=(1, 1), stride=(1, 1)) # Change the output to 3 classes instead of 21\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2s-gk4B3EsEr",
        "outputId": "5ea90a64-eca6-41fd-bc95-9272a1567577"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainable layers: 75\n",
            "Non-trainable layers: 87\n"
          ]
        }
      ],
      "source": [
        "trainable_layers = 0\n",
        "non_trainable_layers = 0\n",
        "\n",
        "for name, module in model.named_modules():\n",
        "    # Check if any parameter in the layer requires gradients\n",
        "    if any(param.requires_grad for param in module.parameters()):\n",
        "        trainable_layers += 1\n",
        "    else:\n",
        "        non_trainable_layers += 1\n",
        "\n",
        "print(f\"Trainable layers: {trainable_layers}\")\n",
        "print(f\"Non-trainable layers: {non_trainable_layers}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoRmM5y3EsEr",
        "outputId": "322824e9-04f0-4f38-cd24-5baf884d4369"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainable parameters: 9485187\n",
            "Non-trainable parameters: 25827797\n"
          ]
        }
      ],
      "source": [
        "\n",
        "trainable_params = 0\n",
        "non_trainable_params = 0\n",
        "\n",
        "for param in model.parameters():\n",
        "    if param.requires_grad:\n",
        "        trainable_params += param.numel()  # Count the number of elements\n",
        "    else:\n",
        "        non_trainable_params += param.numel()\n",
        "\n",
        "print(f\"Trainable parameters: {trainable_params}\")\n",
        "print(f\"Non-trainable parameters: {non_trainable_params}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOSg-1m7EsEt"
      },
      "source": [
        "## Training Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ns4tJ9HoEsEt"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "\n",
        "# optimizer = optim.Adam(\n",
        "#     filter(lambda p: p.requires_grad, model.parameters()),\n",
        "#     lr=0.001\n",
        "# )\n",
        "\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs=1):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr = 3e-4) # Karpathy's number\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            # Move data to GPU if available\n",
        "            if torch.cuda.is_available():\n",
        "                images = images.cuda()\n",
        "                labels = labels.type(torch.LongTensor).cuda()\n",
        "                model.cuda()\n",
        "\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)['out']\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Zero gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            #running_loss += loss.item() * images.size(0)\n",
        "        test_loss = evaluate_model(model, val_loader)\n",
        "        #epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Accuracy: {test_loss:.4f}')\n",
        "\n",
        "def evaluate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_pixels = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            if torch.cuda.is_available():\n",
        "                images = images.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "            outputs = model(images)['out']\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            total_pixels += labels.numel()\n",
        "            total_correct += (preds == labels).sum().item()\n",
        "\n",
        "        accuracy = total_correct / total_pixels\n",
        "        return accuracy\n",
        "        #print(f'Validation Accuracy: {accuracy:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmklZldlEsEu"
      },
      "source": [
        "## Data Prep Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ClR6aVHHEsEu"
      },
      "outputs": [],
      "source": [
        "# Custom dataset class for your data\n",
        "import torchvision.transforms as transforms\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "rgb_to_class = {\n",
        "    (0, 0, 0): 0,\n",
        "    (255, 255, 255): 1,\n",
        "    (100, 100, 100): 2\n",
        "}\n",
        "\n",
        "class JointTransform:\n",
        "    def __init__(self, image_transforms=None, mask_transforms=None):\n",
        "        self.image_transforms = image_transforms\n",
        "        self.mask_transforms = mask_transforms\n",
        "    @staticmethod\n",
        "    def set_seed(seed):\n",
        "      torch.manual_seed(seed)\n",
        "      torch.cuda.manual_seed(seed)\n",
        "      torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
        "      random.seed(seed)\n",
        "      np.random.seed(seed)\n",
        "\n",
        "      # Ensure that all operations are deterministic\n",
        "      torch.backends.cudnn.deterministic = True\n",
        "      torch.backends.cudnn.benchmark = False\n",
        "    def __call__(self, image, mask):\n",
        "        if self.image_transforms:\n",
        "            seed = random.randint(0, 2**32)\n",
        "            self.set_seed(seed)\n",
        "            image = self.image_transforms(image)\n",
        "\n",
        "            self.set_seed(seed)\n",
        "            mask = self.mask_transforms(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "image_augmentations = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.RandomResizedCrop(size=(256, 256), scale=(0.8, 1.0)),\n",
        "])\n",
        "\n",
        "mask_augmentations = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.RandomResizedCrop(size=(256, 256), scale=(0.8, 1.0)),\n",
        "])\n",
        "\n",
        "# Instantiate joint transform\n",
        "augmentation = JointTransform(image_transforms=image_augmentations, mask_transforms=mask_augmentations)\n",
        "\n",
        "\n",
        "class Potholes(Dataset):\n",
        "    def __init__(self, image_dir, label_dir, do_augmentation = True):\n",
        "        self.image_dir = image_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.image_filenames = os.listdir(image_dir)\n",
        "        self.mean = (0.485, 0.456, 0.406)\n",
        "        self.std = (0.229, 0.224, 0.225)\n",
        "        self.do_augmentation = do_augmentation\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "    @staticmethod\n",
        "    def rgb_to_mask(mask):\n",
        "        # Convert the mask to a numpy array\n",
        "        mask = np.array(mask)\n",
        "\n",
        "        # Initialize an array to hold the class indices\n",
        "        class_mask = np.zeros((mask.shape[0], mask.shape[1]), dtype=np.uint8)\n",
        "\n",
        "        # Apply the mapping from RGB values to class indices\n",
        "        for rgb, class_index in rgb_to_class.items():\n",
        "            matches = np.all(mask == rgb, axis=-1)\n",
        "            class_mask[matches] = class_index\n",
        "\n",
        "        return class_mask\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_filenames[idx]\n",
        "        img_path = os.path.join(self.image_dir, img_name)\n",
        "        label_path = os.path.join(self.label_dir, (img_name[:-4] + \"_mask.png\"))\n",
        "\n",
        "        # Load image and label\n",
        "        image = Image.open(img_path)\n",
        "        mask = Image.open(label_path).convert(\"RGB\")\n",
        "\n",
        "        # Apply augmentations then transformations\n",
        "\n",
        "        if self.do_augmentation: image, mask = augmentation(image, mask)\n",
        "\n",
        "        image, mask = self.image_transforms(image, mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "# Define transforms for data augmentation and normalization\n",
        "\n",
        "    def image_transforms(self, image, label):\n",
        "        transform_images = transforms.Compose([\n",
        "            transforms.Resize((256, 256)),  # Resize to the desired input size\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(self.mean, self.std)\n",
        "        ])\n",
        "\n",
        "        transform_labels = transforms.Compose([\n",
        "            transforms.Resize((256, 256))\n",
        "        ])\n",
        "        mask = self.rgb_to_mask(transform_labels(label))\n",
        "        return transform_images(image), mask\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Paths to your dataset\n",
        "train_image_dir = \"./data/train_images_segmented/\"\n",
        "train_label_dir = \"./data/train_masks_segmented/\"\n",
        "\n",
        "val_image_dir = \"./data/validation set/\"\n",
        "val_label_dir = \"./data/validation masks/\"\n",
        "\n",
        "# size of stick/image indicates camera zoom\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "gkGh36k8EsEu",
        "outputId": "a51b5930-8b0e-446c-fb47-b51823ad840f"
      },
      "outputs": [],
      "source": [
        "# Create datasets and data loaders\n",
        "train_dataset = Potholes(train_image_dir, train_label_dir, do_augmentation=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=15, shuffle=True)\n",
        "\n",
        "val_dataset = Potholes(val_image_dir, val_label_dir, do_augmentation=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=15, shuffle=True)\n",
        "\n",
        "#train_model(model = model,train_loader = train_loader,num_epochs= 1000, val_loader=val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ExDTpR72fYNV"
      },
      "outputs": [],
      "source": [
        "\n",
        "import math\n",
        "import torch\n",
        "\n",
        "def find_lr(model, loss_fn, optimizer, train_loader, init_value=1e-8, final_value=10.0):\n",
        "    model.to(\"cuda\")\n",
        "    number_in_epoch = len(train_loader) - 1\n",
        "    update_step = (final_value / init_value) ** (1 / number_in_epoch)\n",
        "    lr = init_value\n",
        "    optimizer.param_groups[0][\"lr\"] = lr\n",
        "    best_loss = float('inf')\n",
        "    batch_num = 0\n",
        "    losses = []\n",
        "    log_lrs = []\n",
        "\n",
        "    for data in train_loader:\n",
        "        batch_num += 1\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs, labels\n",
        "        inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)[\"out\"]\n",
        "        loss = loss_fn(outputs, labels.type(torch.LongTensor).cuda())\n",
        "\n",
        "        # Convert loss to float for comparison and storage\n",
        "        loss_value = loss.item()\n",
        "\n",
        "        # Crash out if loss explodes\n",
        "        if batch_num > 1 and loss_value > 4 * best_loss:\n",
        "            return log_lrs[10:-5], losses[10:-5]\n",
        "\n",
        "        # Record the best loss\n",
        "        if loss_value < best_loss:\n",
        "            best_loss = loss_value\n",
        "\n",
        "        # Store the values\n",
        "        losses.append(loss_value)\n",
        "        log_lrs.append(math.log10(lr))\n",
        "\n",
        "        # Do the backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the lr for the next step and store\n",
        "        lr *= update_step\n",
        "        optimizer.param_groups[0][\"lr\"] = lr\n",
        "\n",
        "    return log_lrs[10:-5], losses[10:-5]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "#logs,losses = find_lr(model, nn.CrossEntropyLoss(), optim.Adam(model.parameters(), lr = 3e-4), train_loader=train_loader)\n",
        "#plt.plot(logs,losses)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_8824/1325712498.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  final_model = torch.load(\"./trained_model.pt\")\n"
          ]
        }
      ],
      "source": [
        "final_model = torch.load(\"./trained_model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "test_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ])\n",
        "test_image = Image.open(\"./data/test set/p108.jpg\").convert(\"RGB\")\n",
        "test_image = test_transform(test_image).cuda().view(1, 3, 256, 256)\n",
        "final_model.eval()\n",
        "out = final_model(test_image)[\"out\"]\n",
        "predicted_mask = torch.argmax(out, dim=1).view(256, 256).cpu()\n",
        "\n",
        "\n",
        "def array_to_image(array):\n",
        "    # Define the mapping from array values to RGB colors\n",
        "    color_mapping = {\n",
        "        0: (0, 0, 0),       # Black\n",
        "        1: (255, 255, 255), # White\n",
        "        2: (128, 128, 128)  # Gray\n",
        "    }\n",
        "    \n",
        "    # Convert the array to an RGB image\n",
        "    height, width = array.shape\n",
        "    image = Image.new('RGB', (width, height))\n",
        "    \n",
        "    for y in range(height):\n",
        "        for x in range(width):\n",
        "            image.putpixel((x, y), color_mapping[array[y, x]])\n",
        "    \n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "class pothole_estimator():\n",
        "    def __init__(self, array):\n",
        "        self.array = array\n",
        "        \n",
        "    def is_valid_two(self, y, x):\n",
        "        \"\"\"Check if the element at (y, x) is a 2 with both 0 and 1 as neighbors.\"\"\"\n",
        "        height, width = self.array.shape\n",
        "        neighbors = []\n",
        "        \n",
        "        # Check all 8 possible neighbors\n",
        "        for dy in [-1, 0, 1]:\n",
        "            for dx in [-1, 0, 1]:\n",
        "                if dy == 0 and dx == 0:\n",
        "                    continue\n",
        "                ny, nx = y + dy, x + dx\n",
        "                if 0 <= ny < height and 0 <= nx < width:\n",
        "                    neighbors.append(self.array[ny, nx])\n",
        "        \n",
        "        return 0 in neighbors and 1 in neighbors\n",
        "    \n",
        "\n",
        "    def find_closest_pair(self, coords):\n",
        "        \"\"\"Find the pair of points in coords that are closest to each other.\"\"\"\n",
        "        min_dist = float('inf')\n",
        "        closest_pair = None\n",
        "        \n",
        "        for i in range(len(coords)):\n",
        "            for j in range(i + 1, len(coords)):\n",
        "                if self.is_adjacent(coords[i], coords[j]):\n",
        "                    continue\n",
        "                dist = np.linalg.norm(np.array(coords[i]) - np.array(coords[j]))\n",
        "                if dist < min_dist:final_array = \n",
        "        \"\"\"Draw a line of 0's between points p1 and p2 using Bresenham's line algorithm.\"\"\"\n",
        "        y1, x1 = p1\n",
        "        y2, x2 = p2\n",
        "        dy = abs(y2 - y1)\n",
        "        dx = abs(x2 - x1)\n",
        "        sy = 1 if y1 < y2 else -1\n",
        "        sx = 1 if x1 < x2 else -1\n",
        "        err = dx - dy\n",
        "\n",
        "        while True:\n",
        "            self.array[y1, x1] = 1\n",
        "            if (y1, x1) == (y2, x2):\n",
        "                break\n",
        "            e2 = 2 * err\n",
        "            if e2 > -dy:\n",
        "                err -= dy\n",
        "                x1 += sx\n",
        "            if e2 < dx:\n",
        "                err += dx\n",
        "                y1 += sy\n",
        "    @staticmethod        \n",
        "    def is_adjacent(p1, p2):\n",
        "        \"\"\"Check if two points p1 and p2 are adjacent (including diagonally).\"\"\"\n",
        "        y1, x1 = p1\n",
        "        y2, x2 = p2\n",
        "        return abs(y1 - y2) <= 1 and abs(x1 - x2) <= 1\n",
        "\n",
        "    def process_array(self):\n",
        "        height, width = self.array.shape\n",
        "        valid_twos = []\n",
        "        \n",
        "        # Step 1: Find all valid 2's\n",
        "        for y in range(height):\n",
        "            for x in range(width):\n",
        "                if self.array[y, x] == 2 and self.is_valid_two(y, x):\n",
        "                    valid_twos.append((y, x))\n",
        "        \n",
        "        # Step 2: Draw lines between closest pairs of valid 2's\n",
        "        while len(valid_twos) > 1:\n",
        "            p1, p2 = self.find_closest_pair(valid_twos)\n",
        "            self.draw_line(p1, p2)\n",
        "            valid_twos.remove(p1)\n",
        "            valid_twos.remove(p2)\n",
        "\n",
        "        return self.array\n",
        "    \n",
        "    def turn_twos_to_zeros_no_diagonals(self):\n",
        "        \"\"\"\n",
        "        Turn all 2's that touch a 0 into a 0, considering only horizontal and vertical neighbors,\n",
        "        and repeat the process until no pixels are changed.\n",
        "        \"\"\"\n",
        "        height, width = self.array.shape\n",
        "        changed = True\n",
        "        \n",
        "        while changed:\n",
        "            changed = False\n",
        "            new_array = self.array.copy()\n",
        "            \n",
        "            for y in range(height):\n",
        "                for x in range(width):\n",
        "                    if self.array[y, x] == 2:\n",
        "                        # Check only 4 possible neighbors (up, down, left, right)\n",
        "                        for dy, dx in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
        "                            ny, nx = y + dy, x + dx\n",
        "                            if 0 <= ny < height and 0 <= nx < width:\n",
        "                                if self.array[ny, nx] == 0:\n",
        "                                    new_array[y, x] = 0\n",
        "                                    changed = True\n",
        "                                    break\n",
        "                                    \n",
        "            self.array = new_array\n",
        "\n",
        "        return self.array\n",
        "    def turn_remaining_twos_to_ones(self):\n",
        "        \"\"\"\n",
        "        Turn all remaining 2's into 1's.\n",
        "        \"\"\"\n",
        "        self.array[self.array == 2] = 1\n",
        "        return self.array\n",
        "\n",
        "\n",
        "estimator = pothole_estimator(np.array(predicted_mask))\n",
        "estimator.process_array()\n",
        "estimator.turn_twos_to_zeros_no_diagonals()\n",
        "final_array = estimator.turn_remaining_twos_to_ones()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "array_to_image(final_array).save(\"output.jpg\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
